# Speech-Emotion-Recognization

data set link :- https://www.kaggle.com/datasets/ejlok1/toronto-emotional-speech-set-tess 
or 
https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio

for feature extraction MFCC(. The MFCC technique involves computing the Mel-frequency spectrum of a signal, which is a logarithmically spaced frequency representation of the signal) and used LSTM model which is a layered approach which consist of 2-3 regularization layer along side the dense layer
later created the model.h5 file for saving down the model so that easily deploy it using streamlit which is open source framework the code for the same is available in app.py file.
